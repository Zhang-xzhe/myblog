---
title: Energy-Efficient Proactive Caching for Fog Computing with Correlated Task Arrivals
date: 2022-4-26
tags:
- MEC
- computation offload
- non-convex
- math
categories:
- Paper
---
# 相关任务到达时云计算的节能主动缓存

## _Abstract_
随着低延迟应用的激增，FRAN（雾无线网络）被认为是能够实现在网络边缘分布式部署克隆云设施的转化范例。

<font size=5>**背景**：</font>本文中，我们考虑有限时间内单用户单接入点的雾计算系统的主动缓存，其中同类应用的连续任务可以看作是暂时相关的。

<font size=5>**问题**：</font>在可以预测任务输入比特数的长度的假设下，在严格的每时隙长度的限制下，我们提出了三个时隙关联共同优化 计算卸载策略和缓存决定的长时间加权能量最小化问题。这个问题的难点在于，它是一个混合整数型非凸问题。

<font size=5>**结果**：</font>为了解决这个问题，我们首先假设了任务相关信息是完全已知的，记为先验。并利用半正定松弛技术提供了离线解，从而确定了理论上限。下一步，基于离线解，我们提出了在任意分布预测误差下基于滑窗的在线算法。最后，通过数值例子比较几个标准证实了计算缓存和提出相应算法的优势。

## _Introduction_

前所未有的泛计算的增长让云计算难以满足他们需求的短延时，因为云计算需要从用户端到终端长距离的传输。为了解决这一点，雾计算腾空出世，它可以解决uRLLC要求下的通信。

雾计算也被称为边缘计算，它赋予了边缘接入点计算和存储的能力。通过这样，一些低功耗的无线设备就可以寻找那些有边缘服务的AP节点，通过卸载一部分任务来实现省能量的实时计算。大量文献已经对网络成本和延时之间的权衡做了研究，达到了满意的效果。

同时，边缘缓存可以让用户从附近的AP获取通用的内容，这可以减缓增长的流量。现在的研究主要集中在提升能够缓存的内容的缓存效率的问题，但是对于那些为了减少重复边缘计算的缓存研究较少。Proactive edge computing in latency-constrained fog networks一文中研究了雾计算中通过主动缓存来实现uRLLC。但是他们假设预先缓存的内容能够被随后的任务完全复用，这在实际中是过于理想化的，因为相比于内容分配，计算服务通常是采用一次性的数据集很难复用。所以，深入理解任务之间本质相关的内容是相当关键的。Joint service caching and task offloading for mobile edge computing in dense networks和Energy efficient task caching and offloading for mobile edge computing两文中研究了服务缓存和卸载计算的联合考虑，但是他们没有建模考虑动态缓存相关任务能给卸载缓存带来增益。

本文中，我们研究一个由一个用户，一个AP组成的雾计算网络的主动缓存技术，在有限时间内的对时间敏感任务相关性充分利用从而使得当前时刻的缓存结果能够在未来时刻用上。据我们所知，这是第一次研究通过联合缓存和计算卸载来最小化长期的加权能量和。在三个连续的时隙间有相关性，对任务输入不完全输入的条件下，首先利用半定松弛提出了一个离线解，这是一个理论上界。接下来，我们提出了一个滑窗启发的考虑了已知预测误差的在线解。最后，数值解显示计算缓存带来了提出的在线算法的效率和性能的显著提升。

在本文中我们使用大写黑体表示矩阵，小写黑体表示向量，用（）*表示矩阵和向量的最优解，用Tr（）表示矩阵的迹。

## _System model and Problem formulation_
我们考虑一个单天线的用户，一个M天线的AP，一个边缘服务器和一个缓存设施组成的雾网络。在时隙i时，用户请求向附近的AP请求一个计算卸载。本文主要考虑有限的时间，每个时隙长度为T，标记为$\Nu = [1,...,N]$，fig1中显示了时间相关的连续序列如何到达用户。

<a href="https://sm.ms/image/tsWp5wMVPeDmRvn" target="_blank"><img src="https://s2.loli.net/2022/05/10/tsWp5wMVPeDmRvn.png" ></a>

我们假设每个任务都需要在每个时隙结束前完成。因为当前时隙的任务是和未来的任务相关的，所以现在时刻任务的计算结果就可以存在AP这儿对未来计算有用。因为缓存会有开销（延时，能量，存储），所以全部存起来是不太好的。因此，我们引入一个变量$I_i,i \in \Nu$来表示时候i时刻需要缓存数据：
$$ I_i=\begin{cases}
   1 &\text{if } cache the result\\
   0 &\text{if } otherwise
\end{cases}$$
所以缓存使能的雾计算系统的工作流程可以描述为：用户将一部分任务放到终端上算，另一部分自己本地算。如果AP觉得没有必要缓存这个数据，那么就传回给用户；否则用户就把剩下的上传给AP。由于AP有足够的传输资源，比如传输功率，所以在后续中我们忽略用户从AP下载时的时延和能量。

### A、用户端的本地执行，运算卸载和计算上传

我们用$L_i$表示i时隙的任务数据的长度，这个长度是可以预测的，但是有误差,可以表示为$ L_i = \hat L_i + \Delta L_i$，其中$\Delta L_i$是一个任意的序列（可以是确定的，也可以是随机的）。在时隙i时，所有i时刻以及i时刻前的输入数据长度AP是知道的，但是i时隙之后的只有在未来才知道。我们将需要在i时隙计算的比特用前面时候是否缓存的决定来表示：
$$D_i = L_i(I_{i-1} \tau_1+...+\prod_{j-1}^{k-1}(1-I_{i-j})I_{i-k}\tau_k+...
+\prod_{j=1}^{r-1}(1-I_{i-j})I_{i-r}\tau_r+\prod_{j=1}^{r}(1-I_{i-j}))$$