---
title: Energy-Efficient Mobile-Edge Computation Offloading for Applications With Shared Date
date: 2022-4-26
tags:
- MEC
- computation offload
- convex
- math
categories:
- Paper
---

# 共享数据的应用的节能MECO

## _Abstract_
MECO（移动边缘计算卸载）可以帮助计算能力不强的IOT设备缓解计算压力，而且对于一些用户共享相似的数据。基于这两大特征，本文主要解决：

<font size=5>**背景**：</font>在一个多用户的云系统中，一些有着共享数据的单天线移动用户可以选择将部分数据放到朵云上算或者全部本地算。

<font size=5>**问题**：</font>在总计算延迟受限、个体用户下载数据总能量受限，以及本地计算处理的频率受限的条件下，移动用户能量最小化是一个凸问题，可以用classical lagrangian duality找到最优解。

<font size=5>**结果**：</font>基于这样的半闭式解，证明只能由一个用户发出共享数据，而不是多个。除此之外，与那些没有考虑用户本地计算能力和共享数据特性的基础算法相比，本文提出的联合计算卸载与通信资源分配节约了大量的能量

## _Introduction_

<font size=5>**背景**：</font>随着IOT时代的到来，移动云计算很难满足大量增长的时延敏感型应用。为了适应这些需求、减轻负载，在无线接入网中，回程网络（即MEC）也可以叫做雾计算已经开始将云计算能力扩展到网络边缘。

<font size=5>**研究现状**：</font>工业界和学术界都致力于为下一代通信系统提供uRLLC（高可靠低时延通信）。在工业界前辈们探索雾计算中，思科（Cisco）提出雾计算很可能是下一代IOT的架构。学术界中，一部分人关注一个移动用户到一个朵云的点到点的计算卸载计划。另一部分人提出多个边缘服务器的多用户场景，同时部分人研究多个用户到一个基站服务器的多对一研究。

最近有人在研究计算卸载中AR等应用的内在合作属性。事实上，很多移动应用比如AR，VR都是多个用户共享很多数据，所以是有可能让他们的延迟降低的。在某文章中说明了社交VR移动网络中的互相影响，并通过优化方法大量降低了端到端延时。另一篇文章也提到了VR中空间数据的相关性可以最小化完成计算的延时。

在另一边，计算卸载和通信资源（功率，带宽，速率）的联合优化是可以通过明确考虑信道条件和通信限制来提高雾计算的通信性能。在早期的研究中，卸载策略是只估计带宽速率而不考虑通信资源和信道条件。对于通信知晓的设备计算卸载，有学者在多用户合作场景下最小化本地用户延迟，同时也有人最小化雾计算远端的节点能耗。但是他们都没有结合上一段中用户共享信道的特点。

<font size=5>**本文贡献**：</font>所以本文中我们考虑一个多用户雾计算系统，其中运行共享数据应用的多个单天线用户可以选择全部本地计算，或者部分上传给服务器，然后服务器返回结果。通过联合优化计算卸载和通信资源分配，移动用户的能量消耗可以最小化。与现存的文献比较，虽然已经有人研究过共享数据的计算卸载问题，但是没有找到最优解。除此之外，也没有给出信道环境对计算卸载的相关结论。从这点来看，我们的工作提供了一个在MEC系统中共享数据的计算卸载问题的深入思考。

## _System Model_

我们考虑一个由U个运行着AR应用的移动用户（标记为$U$=(1,2……,U)）和一个装备了计算设施作为朵云工作的基站组成的移动边缘系统。所有用户和基站都是单天线。

用户u的输入数据大小记为$D^I_{u},\forall u\in U$。每个用户的数据分为两部分，一部分是自己独特的数据，一部分是共享数据。共享数据是所有用户相同的记作$D^I_{S}$。自己的独特数据一部分将在本地计算，另一部分将送往云端。本地计算的那一部分记作$D^L_{u}$。送往云端的那一部分为$\overline{D}^I_{u}=D^I_{u}-D^I_{S}-D^L_{u},\forall u\in U$。共享数据也需要送往云端，每个用户向云端送一部分，记作$D^I_{u,S} \forall,u\in U$。且满足关系：$\sum ^U_{u=1}D^I_{u,S}=D^I_{S}$

<a href="https://sm.ms/image/lpHceMjqdhD1EKf" target="_blank"><img src="https://s2.loli.net/2022/04/30/lpHceMjqdhD1EKf.png" ></a>

可以从fig1中看出在输入数据卸载阶段和结果下载这两个阶段都有两个子阶段：共享部分和自己部分的传输。卸载时，共享部分的时间记为$t^{ul}_{u,S}$,自己部分的时间为$t^{ul}_u$;下载时，共享部分的时间记作$t^{dl}_{u,S}$,自己部分的时间为$t^{dl}_u$。云端计算的时间同样也显示在云端中：共享部分计算的时间为$t^{C}_{S}$,个人计算的时间为$t^{C}_u$。$F$为朵云给共享数据分配的计算频率，$f_{u}$是朵云给个人数据分配的计算频率。本地的计算时间被记作：$t^C_{u,L}$

<font size=5>**A.上行链路**：</font>

正如fig1所示，上行链路有两个子阶段：共享部分和个人部分。用户通过FDMA上传数据。每个用户的s上行信道系数记作$h_{u}$，假设上行期间不变。共享数据上行传输功率记作$P^{ul}_{u,S}$,根据香农公式，最大传输速率可以计算得：

$$ R^{ul}_{u,S} = W^{ul}_ulog_2(1+\frac{P^{ul}_{u,S}|h_u|^2}{N_0}) $$

其中$W^{ul}_u=\frac{W^{ul}}{U}$,其中$W^{ul}$是上行的整个带宽，$N_0$是AWGN信道中的高斯白噪声的功率。因此可以计算每个用户共享部分传输时间以及能量：

$$ t^{ul}_{u,S}=D^I_{u,S}/R^{ul}_{u,S} $$
$$ E^{ul}_{u,S}=t^{ul}_{u,S}P^{ul}_{u,S}=\frac{t^{ul}_{u,S}}{|h_u|^2}f(\frac{D^I_{u,S}}{t^{ul}_{u,S}}) $$
$$ f(x)=N^0(2^{\frac{x}{W^{ul}_u}}-1) $$

同样的，用户个人数据部分消耗的能量可以表示为：
$$ E^{ul}_{u}=t^{ul}_{u}P^{ul}_{u}=\frac{t^{ul}_{u}}{|h_u|^2}f(\frac{D^I_{u}-D^I_{S}-D^L_{u}}{t^{ul}_{u}}) $$

<font size=5>**B.计算模型**：</font>

基于某文章中的能量模型，本地计算$D^L_{u}$的数据量需要的能耗可以表示为：
$$ E^C_{u}=\kappa_0\frac{(\lambda_0D^L_u)^3}{{t^C_{u,L}}^2} $$

其中$\lambda_0$表示CPU计算1bit数据需要的时钟周期，$\kappa_0$是能耗电容系数。

<font size=5>**C.下行链路**：</font>
跟上行链路相似，下行也是两个子阶段：共享部分和个人部分。共享部分朵云用最大功率$P_{max}$多播给用户。下行速率可以计算为：

$$ R^{dl}_{u,S}=W^{dl}_ulog_2(1+\frac{P_{max}{|g_u|}^2}{N_0}) $$

